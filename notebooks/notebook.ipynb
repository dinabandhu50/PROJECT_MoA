{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('../data/lish-moa/train_features.csv')\n",
    "train_targets = pd.read_csv('../data/lish-moa/train_targets_scored.csv')\n",
    "test_features = pd.read_csv('../data/lish-moa/test_features.csv')\n",
    "\n",
    "ss = pd.read_csv('../data/lish-moa/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    df = df.copy()\n",
    "    df.loc[:, 'cp_type'] = df.loc[:, 'cp_type'].map({'trt_cp': 0, 'ctl_vehicle': 1})\n",
    "    df.loc[:, 'cp_dose'] = df.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n",
    "    del df['sig_id']\n",
    "    return df\n",
    "\n",
    "train = preprocess(train_features)\n",
    "test = preprocess(test_features)\n",
    "\n",
    "del train_targets['sig_id']\n",
    "\n",
    "train_targets = train_targets.loc[train['cp_type']==0].reset_index(drop=True)\n",
    "train = train.loc[train['cp_type']==0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfolds = 7\n",
    "nstarts = 1\n",
    "nepochs = 50\n",
    "batch_size = 128\n",
    "val_batch_size = batch_size * 4\n",
    "ntargets = train_targets.shape[1]\n",
    "targets = [col for col in train_targets.columns]\n",
    "criterion = nn.BCELoss()\n",
    "kfold = MultilabelStratifiedKFold(n_splits=7, random_state=42, shuffle=True)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoaModel(nn.Module):\n",
    "    def __init__(self, num_columns):\n",
    "        super(MoaModel, self).__init__()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_columns)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.dense1 = nn.utils.weight_norm(nn.Linear(num_columns, 2048))\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(2048)\n",
    "        self.dropout2 = nn.Dropout(0.7)\n",
    "        self.dense2 = nn.utils.weight_norm(nn.Linear(2048, 1048))\n",
    "        \n",
    "        self.batch_norm3 = nn.BatchNorm1d(1048)\n",
    "        self.dropout3 = nn.Dropout(0.7)\n",
    "        self.dense3 = nn.utils.weight_norm(nn.Linear(1048, 206))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.dense1(x))\n",
    "        \n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.dense2(x))\n",
    "        \n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = F.sigmoid(self.dense3(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "785\n"
     ]
    }
   ],
   "source": [
    "top_feats = [  1,   2,   3,   4,   5,   6,   7,   9,  11,  14,  15,  16,  17,\n",
    "        18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  29,  30,  31,\n",
    "        32,  33,  35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  46,\n",
    "        47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  58,  59,  60,\n",
    "        61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,\n",
    "        74,  75,  76,  78,  79,  80,  81,  82,  83,  84,  86,  87,  88,\n",
    "        89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101,\n",
    "       102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
    "       115, 116, 117, 118, 120, 121, 122, 123, 124, 125, 126, 127, 128,\n",
    "       129, 130, 131, 132, 133, 136, 137, 138, 139, 140, 141, 142, 143,\n",
    "       144, 145, 146, 147, 149, 150, 151, 152, 153, 154, 155, 156, 157,\n",
    "       158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170,\n",
    "       171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
    "       184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 197,\n",
    "       198, 199, 200, 202, 203, 204, 205, 206, 208, 209, 210, 211, 212,\n",
    "       213, 214, 215, 216, 217, 218, 219, 220, 221, 223, 224, 225, 226,\n",
    "       227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
    "       240, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
    "       254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266,\n",
    "       267, 268, 269, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280,\n",
    "       281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 294,\n",
    "       295, 296, 298, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309,\n",
    "       310, 311, 312, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323,\n",
    "       324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336,\n",
    "       337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
    "       350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
    "       363, 364, 365, 366, 367, 368, 369, 370, 371, 374, 375, 376, 377,\n",
    "       378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 391,\n",
    "       392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404,\n",
    "       405, 406, 407, 408, 409, 411, 412, 413, 414, 415, 416, 417, 418,\n",
    "       419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431,\n",
    "       432, 434, 435, 436, 437, 438, 439, 440, 442, 443, 444, 445, 446,\n",
    "       447, 448, 449, 450, 453, 454, 456, 457, 458, 459, 460, 461, 462,\n",
    "       463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
    "       476, 477, 478, 479, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
    "       490, 491, 492, 493, 494, 495, 496, 498, 500, 501, 502, 503, 505,\n",
    "       506, 507, 509, 510, 511, 512, 513, 514, 515, 518, 519, 520, 521,\n",
    "       522, 523, 524, 525, 526, 527, 528, 530, 531, 532, 534, 535, 536,\n",
    "       538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 549, 550, 551,\n",
    "       552, 554, 557, 559, 560, 561, 562, 565, 566, 567, 568, 569, 570,\n",
    "       571, 572, 573, 574, 575, 577, 578, 580, 581, 582, 583, 584, 585,\n",
    "       586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 599,\n",
    "       600, 601, 602, 606, 607, 608, 609, 611, 612, 613, 615, 616, 617,\n",
    "       618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630,\n",
    "       631, 632, 633, 634, 635, 636, 637, 638, 639, 641, 642, 643, 644,\n",
    "       645, 646, 647, 648, 649, 650, 651, 652, 654, 655, 656, 658, 659,\n",
    "       660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672,\n",
    "       673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685,\n",
    "       686, 687, 688, 689, 691, 692, 693, 694, 695, 696, 697, 699, 700,\n",
    "       701, 702, 704, 705, 707, 708, 709, 710, 711, 713, 714, 716, 717,\n",
    "       718, 720, 721, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732,\n",
    "       733, 734, 735, 737, 738, 739, 740, 742, 743, 744, 745, 746, 747,\n",
    "       748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 759, 760, 761,\n",
    "       762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774,\n",
    "       775, 776, 777, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788,\n",
    "       789, 790, 792, 793, 794, 795, 796, 797, 798, 800, 801, 802, 803,\n",
    "       804, 805, 806, 808, 809, 811, 813, 814, 815, 816, 817, 818, 819,\n",
    "       821, 822, 823, 825, 826, 827, 828, 829, 830, 831, 832, 834, 835,\n",
    "       837, 838, 839, 840, 841, 842, 845, 846, 847, 848, 850, 851, 852,\n",
    "       854, 855, 856, 858, 859, 860, 861, 862, 864, 866, 867, 868, 869,\n",
    "       870, 871, 872, 873, 874]\n",
    "print(len(top_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data class\n",
    "class MoaDataset(Dataset):\n",
    "    def __init__(self, df, targets, feats_idx, mode='train'):\n",
    "        self.mode = mode\n",
    "        self.feats = feats_idx\n",
    "        self.data = df[:, feats_idx]\n",
    "        if mode=='train':\n",
    "            self.targets = targets\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == 'train':\n",
    "            return torch.FloatTensor(self.data[idx]), torch.FloatTensor(self.targets[idx])\n",
    "        elif self.mode == 'test':\n",
    "            return torch.FloatTensor(self.data[idx]), 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.values\n",
    "test = test.values\n",
    "train_targets = train_targets.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train seed 0\n",
      "Train fold 1\n",
      "Epoch 1/50   -   loss: 0.42458   -   val_loss: 0.08500\n",
      "Epoch 2/50   -   loss: 0.04969   -   val_loss: 0.02951\n",
      "Epoch 3/50   -   loss: 0.02870   -   val_loss: 0.02327\n",
      "Epoch 4/50   -   loss: 0.02359   -   val_loss: 0.02097\n",
      "Epoch 5/50   -   loss: 0.02208   -   val_loss: 0.02044\n",
      "Epoch 6/50   -   loss: 0.02153   -   val_loss: 0.01970\n",
      "Epoch 7/50   -   loss: 0.02065   -   val_loss: 0.01921\n",
      "Epoch 8/50   -   loss: 0.02024   -   val_loss: 0.01886\n",
      "Epoch 9/50   -   loss: 0.01969   -   val_loss: 0.01858\n",
      "Epoch 10/50   -   loss: 0.01943   -   val_loss: 0.01835\n",
      "Epoch 11/50   -   loss: 0.01915   -   val_loss: 0.01800\n",
      "Epoch 12/50   -   loss: 0.01882   -   val_loss: 0.01769\n",
      "Epoch 13/50   -   loss: 0.01857   -   val_loss: 0.01757\n",
      "Epoch 14/50   -   loss: 0.01833   -   val_loss: 0.01745\n",
      "Epoch 15/50   -   loss: 0.01817   -   val_loss: 0.01726\n",
      "Epoch 16/50   -   loss: 0.01775   -   val_loss: 0.01688\n",
      "Epoch 17/50   -   loss: 0.01770   -   val_loss: 0.01686\n",
      "Epoch 18/50   -   loss: 0.01747   -   val_loss: 0.01685\n",
      "Epoch 19/50   -   loss: 0.01759   -   val_loss: 0.01699\n",
      "Epoch 20/50   -   loss: 0.01740   -   val_loss: 0.01670\n",
      "Epoch 21/50   -   loss: 0.01717   -   val_loss: 0.01658\n",
      "Epoch 22/50   -   loss: 0.01706   -   val_loss: 0.01649\n",
      "Epoch 23/50   -   loss: 0.01688   -   val_loss: 0.01642\n",
      "Epoch 24/50   -   loss: 0.01676   -   val_loss: 0.01635\n",
      "Epoch 25/50   -   loss: 0.01671   -   val_loss: 0.01632\n",
      "Epoch 26/50   -   loss: 0.01670   -   val_loss: 0.01634\n",
      "Epoch 27/50   -   loss: 0.01664   -   val_loss: 0.01629\n",
      "Epoch 28/50   -   loss: 0.01662   -   val_loss: 0.01620\n",
      "Epoch 29/50   -   loss: 0.01653   -   val_loss: 0.01628\n",
      "Epoch 30/50   -   loss: 0.01648   -   val_loss: 0.01615\n",
      "Epoch 31/50   -   loss: 0.01643   -   val_loss: 0.01626\n",
      "Epoch 32/50   -   loss: 0.01640   -   val_loss: 0.01616\n",
      "Epoch 33/50   -   loss: 0.01643   -   val_loss: 0.01616\n",
      "Epoch 34/50   -   loss: 0.01641   -   val_loss: 0.01612\n",
      "Epoch 35/50   -   loss: 0.01640   -   val_loss: 0.01615\n",
      "Epoch 36/50   -   loss: 0.01640   -   val_loss: 0.01612\n",
      "Epoch 37/50   -   loss: 0.01639   -   val_loss: 0.01609\n",
      "Epoch 38/50   -   loss: 0.01637   -   val_loss: 0.01615\n",
      "Epoch 39/50   -   loss: 0.01644   -   val_loss: 0.01621\n",
      "Epoch 40/50   -   loss: 0.01633   -   val_loss: 0.01618\n",
      "Epoch 41/50   -   loss: 0.01638   -   val_loss: 0.01616\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 42/50   -   loss: 0.01605   -   val_loss: 0.01597\n",
      "Epoch 43/50   -   loss: 0.01586   -   val_loss: 0.01592\n",
      "Epoch 44/50   -   loss: 0.01574   -   val_loss: 0.01588\n",
      "Epoch 45/50   -   loss: 0.01565   -   val_loss: 0.01587\n",
      "Epoch 46/50   -   loss: 0.01559   -   val_loss: 0.01584\n",
      "Epoch 47/50   -   loss: 0.01547   -   val_loss: 0.01582\n",
      "Epoch 48/50   -   loss: 0.01541   -   val_loss: 0.01579\n",
      "Epoch 49/50   -   loss: 0.01534   -   val_loss: 0.01574\n",
      "Epoch 50/50   -   loss: 0.01527   -   val_loss: 0.01575\n",
      "Train fold 2\n",
      "Epoch 1/50   -   loss: 0.42597   -   val_loss: 0.08695\n",
      "Epoch 2/50   -   loss: 0.05029   -   val_loss: 0.03013\n",
      "Epoch 3/50   -   loss: 0.02761   -   val_loss: 0.02216\n",
      "Epoch 4/50   -   loss: 0.02352   -   val_loss: 0.02123\n",
      "Epoch 5/50   -   loss: 0.02210   -   val_loss: 0.01964\n",
      "Epoch 6/50   -   loss: 0.02119   -   val_loss: 0.01902\n",
      "Epoch 7/50   -   loss: 0.02084   -   val_loss: 0.01906\n",
      "Epoch 8/50   -   loss: 0.02022   -   val_loss: 0.01825\n",
      "Epoch 9/50   -   loss: 0.02026   -   val_loss: 0.01802\n",
      "Epoch 10/50   -   loss: 0.01932   -   val_loss: 0.01777\n",
      "Epoch 11/50   -   loss: 0.01901   -   val_loss: 0.01745\n",
      "Epoch 12/50   -   loss: 0.01875   -   val_loss: 0.01722\n",
      "Epoch 13/50   -   loss: 0.01850   -   val_loss: 0.01714\n",
      "Epoch 14/50   -   loss: 0.01823   -   val_loss: 0.01696\n",
      "Epoch 15/50   -   loss: 0.01833   -   val_loss: 0.01691\n",
      "Epoch 16/50   -   loss: 0.01785   -   val_loss: 0.01680\n",
      "Epoch 17/50   -   loss: 0.01772   -   val_loss: 0.01663\n",
      "Epoch 18/50   -   loss: 0.01748   -   val_loss: 0.01656\n",
      "Epoch 19/50   -   loss: 0.01733   -   val_loss: 0.01650\n",
      "Epoch 20/50   -   loss: 0.01726   -   val_loss: 0.01643\n",
      "Epoch 21/50   -   loss: 0.01710   -   val_loss: 0.01634\n",
      "Epoch 22/50   -   loss: 0.01697   -   val_loss: 0.01633\n",
      "Epoch 23/50   -   loss: 0.01690   -   val_loss: 0.01626\n",
      "Epoch 24/50   -   loss: 0.01681   -   val_loss: 0.01618\n",
      "Epoch 25/50   -   loss: 0.01676   -   val_loss: 0.01616\n",
      "Epoch 26/50   -   loss: 0.01666   -   val_loss: 0.01620\n",
      "Epoch 27/50   -   loss: 0.01657   -   val_loss: 0.01612\n",
      "Epoch 28/50   -   loss: 0.01655   -   val_loss: 0.01611\n",
      "Epoch 29/50   -   loss: 0.01651   -   val_loss: 0.01606\n",
      "Epoch 30/50   -   loss: 0.01655   -   val_loss: 0.01600\n",
      "Epoch 31/50   -   loss: 0.01645   -   val_loss: 0.01601\n",
      "Epoch 32/50   -   loss: 0.01643   -   val_loss: 0.01599\n",
      "Epoch 33/50   -   loss: 0.01634   -   val_loss: 0.01603\n",
      "Epoch 34/50   -   loss: 0.01639   -   val_loss: 0.01603\n",
      "Epoch 35/50   -   loss: 0.01637   -   val_loss: 0.01604\n",
      "Epoch 36/50   -   loss: 0.01632   -   val_loss: 0.01601\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 37/50   -   loss: 0.01601   -   val_loss: 0.01588\n",
      "Epoch 38/50   -   loss: 0.01581   -   val_loss: 0.01582\n",
      "Epoch 39/50   -   loss: 0.01564   -   val_loss: 0.01580\n",
      "Epoch 40/50   -   loss: 0.01556   -   val_loss: 0.01576\n",
      "Epoch 41/50   -   loss: 0.01548   -   val_loss: 0.01573\n",
      "Epoch 42/50   -   loss: 0.01541   -   val_loss: 0.01574\n",
      "Epoch 43/50   -   loss: 0.01533   -   val_loss: 0.01570\n",
      "Epoch 44/50   -   loss: 0.01529   -   val_loss: 0.01570\n",
      "Epoch 45/50   -   loss: 0.01520   -   val_loss: 0.01568\n",
      "Epoch 46/50   -   loss: 0.01511   -   val_loss: 0.01565\n",
      "Epoch 47/50   -   loss: 0.01507   -   val_loss: 0.01566\n",
      "Epoch 48/50   -   loss: 0.01499   -   val_loss: 0.01565\n",
      "Epoch 49/50   -   loss: 0.01491   -   val_loss: 0.01564\n",
      "Epoch 50/50   -   loss: 0.01485   -   val_loss: 0.01565\n",
      "Train fold 3\n",
      "Epoch 1/50   -   loss: 0.42472   -   val_loss: 0.08670\n",
      "Epoch 2/50   -   loss: 0.05097   -   val_loss: 0.03012\n",
      "Epoch 3/50   -   loss: 0.02757   -   val_loss: 0.02333\n",
      "Epoch 4/50   -   loss: 0.02365   -   val_loss: 0.02101\n",
      "Epoch 5/50   -   loss: 0.02199   -   val_loss: 0.02054\n",
      "Epoch 6/50   -   loss: 0.02099   -   val_loss: 0.01942\n",
      "Epoch 7/50   -   loss: 0.02042   -   val_loss: 0.01912\n",
      "Epoch 8/50   -   loss: 0.02010   -   val_loss: 0.01900\n",
      "Epoch 9/50   -   loss: 0.01969   -   val_loss: 0.01841\n",
      "Epoch 10/50   -   loss: 0.01948   -   val_loss: 0.01825\n",
      "Epoch 11/50   -   loss: 0.01900   -   val_loss: 0.01802\n",
      "Epoch 12/50   -   loss: 0.01886   -   val_loss: 0.01797\n",
      "Epoch 13/50   -   loss: 0.01849   -   val_loss: 0.01763\n",
      "Epoch 14/50   -   loss: 0.01824   -   val_loss: 0.01736\n",
      "Epoch 15/50   -   loss: 0.01804   -   val_loss: 0.01722\n",
      "Epoch 16/50   -   loss: 0.01784   -   val_loss: 0.01724\n",
      "Epoch 17/50   -   loss: 0.01765   -   val_loss: 0.01704\n",
      "Epoch 18/50   -   loss: 0.01750   -   val_loss: 0.01688\n",
      "Epoch 19/50   -   loss: 0.01739   -   val_loss: 0.01682\n",
      "Epoch 20/50   -   loss: 0.01720   -   val_loss: 0.01678\n",
      "Epoch 21/50   -   loss: 0.01710   -   val_loss: 0.01665\n",
      "Epoch 22/50   -   loss: 0.01697   -   val_loss: 0.01658\n",
      "Epoch 23/50   -   loss: 0.01691   -   val_loss: 0.01649\n",
      "Epoch 24/50   -   loss: 0.01675   -   val_loss: 0.01643\n",
      "Epoch 25/50   -   loss: 0.01672   -   val_loss: 0.01640\n",
      "Epoch 26/50   -   loss: 0.01664   -   val_loss: 0.01646\n",
      "Epoch 27/50   -   loss: 0.01656   -   val_loss: 0.01634\n",
      "Epoch 28/50   -   loss: 0.01655   -   val_loss: 0.01626\n",
      "Epoch 29/50   -   loss: 0.01653   -   val_loss: 0.01633\n",
      "Epoch 30/50   -   loss: 0.01644   -   val_loss: 0.01631\n",
      "Epoch 31/50   -   loss: 0.01644   -   val_loss: 0.01626\n",
      "Epoch 32/50   -   loss: 0.01642   -   val_loss: 0.01624\n",
      "Epoch 33/50   -   loss: 0.01641   -   val_loss: 0.01637\n",
      "Epoch 34/50   -   loss: 0.01638   -   val_loss: 0.01628\n",
      "Epoch 35/50   -   loss: 0.01635   -   val_loss: 0.01620\n",
      "Epoch 36/50   -   loss: 0.01638   -   val_loss: 0.01624\n",
      "Epoch 37/50   -   loss: 0.01638   -   val_loss: 0.01629\n",
      "Epoch 38/50   -   loss: 0.01634   -   val_loss: 0.01617\n",
      "Epoch 39/50   -   loss: 0.01634   -   val_loss: 0.01622\n",
      "Epoch 40/50   -   loss: 0.01634   -   val_loss: 0.01630\n",
      "Epoch 41/50   -   loss: 0.01638   -   val_loss: 0.01626\n",
      "Epoch 42/50   -   loss: 0.01632   -   val_loss: 0.01632\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 43/50   -   loss: 0.01602   -   val_loss: 0.01612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50   -   loss: 0.01575   -   val_loss: 0.01606\n",
      "Epoch 45/50   -   loss: 0.01567   -   val_loss: 0.01603\n",
      "Epoch 46/50   -   loss: 0.01561   -   val_loss: 0.01595\n",
      "Epoch 47/50   -   loss: 0.01547   -   val_loss: 0.01594\n",
      "Epoch 48/50   -   loss: 0.01542   -   val_loss: 0.01594\n",
      "Epoch 49/50   -   loss: 0.01538   -   val_loss: 0.01590\n",
      "Epoch 50/50   -   loss: 0.01524   -   val_loss: 0.01591\n",
      "Train fold 4\n",
      "Epoch 1/50   -   loss: 0.42322   -   val_loss: 0.08156\n",
      "Epoch 2/50   -   loss: 0.05022   -   val_loss: 0.02883\n",
      "Epoch 3/50   -   loss: 0.02754   -   val_loss: 0.02313\n",
      "Epoch 4/50   -   loss: 0.02397   -   val_loss: 0.02071\n",
      "Epoch 5/50   -   loss: 0.02213   -   val_loss: 0.01974\n",
      "Epoch 6/50   -   loss: 0.02113   -   val_loss: 0.01927\n",
      "Epoch 7/50   -   loss: 0.02103   -   val_loss: 0.01884\n",
      "Epoch 8/50   -   loss: 0.02009   -   val_loss: 0.01832\n",
      "Epoch 9/50   -   loss: 0.01984   -   val_loss: 0.01817\n",
      "Epoch 10/50   -   loss: 0.01939   -   val_loss: 0.01776\n",
      "Epoch 11/50   -   loss: 0.01908   -   val_loss: 0.01764\n",
      "Epoch 12/50   -   loss: 0.01868   -   val_loss: 0.01734\n",
      "Epoch 13/50   -   loss: 0.01835   -   val_loss: 0.01715\n",
      "Epoch 14/50   -   loss: 0.01824   -   val_loss: 0.01705\n",
      "Epoch 15/50   -   loss: 0.01806   -   val_loss: 0.01684\n",
      "Epoch 16/50   -   loss: 0.01785   -   val_loss: 0.01675\n",
      "Epoch 17/50   -   loss: 0.01761   -   val_loss: 0.01667\n",
      "Epoch 18/50   -   loss: 0.01750   -   val_loss: 0.01661\n",
      "Epoch 19/50   -   loss: 0.01733   -   val_loss: 0.01655\n",
      "Epoch 20/50   -   loss: 0.01727   -   val_loss: 0.01644\n",
      "Epoch 21/50   -   loss: 0.01713   -   val_loss: 0.01637\n",
      "Epoch 22/50   -   loss: 0.01701   -   val_loss: 0.01629\n",
      "Epoch 23/50   -   loss: 0.01681   -   val_loss: 0.01623\n",
      "Epoch 24/50   -   loss: 0.01682   -   val_loss: 0.01609\n",
      "Epoch 25/50   -   loss: 0.01670   -   val_loss: 0.01608\n",
      "Epoch 26/50   -   loss: 0.01664   -   val_loss: 0.01607\n",
      "Epoch 27/50   -   loss: 0.01658   -   val_loss: 0.01608\n",
      "Epoch 28/50   -   loss: 0.01645   -   val_loss: 0.01597\n",
      "Epoch 29/50   -   loss: 0.01646   -   val_loss: 0.01598\n",
      "Epoch 30/50   -   loss: 0.01645   -   val_loss: 0.01599\n",
      "Epoch 31/50   -   loss: 0.01638   -   val_loss: 0.01599\n",
      "Epoch 32/50   -   loss: 0.01643   -   val_loss: 0.01599\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 33/50   -   loss: 0.01603   -   val_loss: 0.01580\n",
      "Epoch 34/50   -   loss: 0.01584   -   val_loss: 0.01578\n",
      "Epoch 35/50   -   loss: 0.01570   -   val_loss: 0.01572\n",
      "Epoch 36/50   -   loss: 0.01561   -   val_loss: 0.01568\n",
      "Epoch 37/50   -   loss: 0.01558   -   val_loss: 0.01565\n",
      "Epoch 38/50   -   loss: 0.01548   -   val_loss: 0.01566\n",
      "Epoch 39/50   -   loss: 0.01538   -   val_loss: 0.01564\n",
      "Epoch 40/50   -   loss: 0.01532   -   val_loss: 0.01564\n",
      "Epoch 41/50   -   loss: 0.01522   -   val_loss: 0.01559\n",
      "Epoch 42/50   -   loss: 0.01515   -   val_loss: 0.01561\n",
      "Epoch 43/50   -   loss: 0.01509   -   val_loss: 0.01561\n",
      "Epoch 44/50   -   loss: 0.01503   -   val_loss: 0.01561\n",
      "Epoch 45/50   -   loss: 0.01500   -   val_loss: 0.01557\n",
      "Epoch 46/50   -   loss: 0.01496   -   val_loss: 0.01559\n",
      "Epoch 47/50   -   loss: 0.01491   -   val_loss: 0.01556\n",
      "Epoch 48/50   -   loss: 0.01481   -   val_loss: 0.01552\n",
      "Epoch 49/50   -   loss: 0.01474   -   val_loss: 0.01560\n",
      "Epoch 50/50   -   loss: 0.01472   -   val_loss: 0.01556\n",
      "Train fold 5\n",
      "Epoch 1/50   -   loss: 0.42779   -   val_loss: 0.08567\n",
      "Epoch 2/50   -   loss: 0.04983   -   val_loss: 0.02917\n",
      "Epoch 3/50   -   loss: 0.02759   -   val_loss: 0.02441\n",
      "Epoch 4/50   -   loss: 0.02372   -   val_loss: 0.02228\n",
      "Epoch 5/50   -   loss: 0.02213   -   val_loss: 0.02048\n",
      "Epoch 6/50   -   loss: 0.02116   -   val_loss: 0.02012\n",
      "Epoch 7/50   -   loss: 0.02046   -   val_loss: 0.01949\n",
      "Epoch 8/50   -   loss: 0.02009   -   val_loss: 0.01922\n",
      "Epoch 9/50   -   loss: 0.01959   -   val_loss: 0.01874\n",
      "Epoch 10/50   -   loss: 0.01947   -   val_loss: 0.01849\n",
      "Epoch 11/50   -   loss: 0.01904   -   val_loss: 0.01836\n",
      "Epoch 12/50   -   loss: 0.01874   -   val_loss: 0.01808\n",
      "Epoch 13/50   -   loss: 0.01838   -   val_loss: 0.01771\n",
      "Epoch 14/50   -   loss: 0.01820   -   val_loss: 0.01768\n",
      "Epoch 15/50   -   loss: 0.01818   -   val_loss: 0.01765\n",
      "Epoch 16/50   -   loss: 0.01774   -   val_loss: 0.01741\n",
      "Epoch 17/50   -   loss: 0.01759   -   val_loss: 0.01736\n",
      "Epoch 18/50   -   loss: 0.01738   -   val_loss: 0.01720\n",
      "Epoch 19/50   -   loss: 0.01730   -   val_loss: 0.01715\n",
      "Epoch 20/50   -   loss: 0.01718   -   val_loss: 0.01708\n",
      "Epoch 21/50   -   loss: 0.01706   -   val_loss: 0.01700\n",
      "Epoch 22/50   -   loss: 0.01703   -   val_loss: 0.01696\n",
      "Epoch 23/50   -   loss: 0.01679   -   val_loss: 0.01685\n",
      "Epoch 24/50   -   loss: 0.01668   -   val_loss: 0.01683\n",
      "Epoch 25/50   -   loss: 0.01668   -   val_loss: 0.01681\n",
      "Epoch 26/50   -   loss: 0.01655   -   val_loss: 0.01676\n",
      "Epoch 27/50   -   loss: 0.01652   -   val_loss: 0.01674\n",
      "Epoch 28/50   -   loss: 0.01652   -   val_loss: 0.01668\n",
      "Epoch 29/50   -   loss: 0.01646   -   val_loss: 0.01661\n",
      "Epoch 30/50   -   loss: 0.01641   -   val_loss: 0.01675\n",
      "Epoch 31/50   -   loss: 0.01639   -   val_loss: 0.01665\n",
      "Epoch 32/50   -   loss: 0.01642   -   val_loss: 0.01670\n",
      "Epoch 33/50   -   loss: 0.01636   -   val_loss: 0.01661\n",
      "Epoch 34/50   -   loss: 0.01631   -   val_loss: 0.01662\n",
      "Epoch 35/50   -   loss: 0.01628   -   val_loss: 0.01661\n",
      "Epoch 36/50   -   loss: 0.01632   -   val_loss: 0.01668\n",
      "Epoch 37/50   -   loss: 0.01631   -   val_loss: 0.01667\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 38/50   -   loss: 0.01591   -   val_loss: 0.01652\n",
      "Epoch 39/50   -   loss: 0.01577   -   val_loss: 0.01644\n",
      "Epoch 40/50   -   loss: 0.01563   -   val_loss: 0.01637\n",
      "Epoch 41/50   -   loss: 0.01555   -   val_loss: 0.01634\n",
      "Epoch 42/50   -   loss: 0.01546   -   val_loss: 0.01629\n",
      "Epoch 43/50   -   loss: 0.01537   -   val_loss: 0.01628\n",
      "Epoch 44/50   -   loss: 0.01533   -   val_loss: 0.01628\n",
      "Epoch 45/50   -   loss: 0.01518   -   val_loss: 0.01625\n",
      "Epoch 46/50   -   loss: 0.01520   -   val_loss: 0.01623\n",
      "Epoch 47/50   -   loss: 0.01511   -   val_loss: 0.01621\n",
      "Epoch 48/50   -   loss: 0.01500   -   val_loss: 0.01619\n",
      "Epoch 49/50   -   loss: 0.01500   -   val_loss: 0.01620\n",
      "Epoch 50/50   -   loss: 0.01493   -   val_loss: 0.01618\n",
      "Train fold 6\n",
      "Epoch 1/50   -   loss: 0.42693   -   val_loss: 0.07920\n",
      "Epoch 2/50   -   loss: 0.05029   -   val_loss: 0.03019\n",
      "Epoch 3/50   -   loss: 0.02800   -   val_loss: 0.02314\n",
      "Epoch 4/50   -   loss: 0.02345   -   val_loss: 0.02058\n",
      "Epoch 5/50   -   loss: 0.02242   -   val_loss: 0.01957\n",
      "Epoch 6/50   -   loss: 0.02122   -   val_loss: 0.01923\n",
      "Epoch 7/50   -   loss: 0.02073   -   val_loss: 0.01859\n",
      "Epoch 8/50   -   loss: 0.02024   -   val_loss: 0.01843\n",
      "Epoch 9/50   -   loss: 0.01990   -   val_loss: 0.01844\n",
      "Epoch 10/50   -   loss: 0.01988   -   val_loss: 0.01860\n",
      "Epoch 11/50   -   loss: 0.01928   -   val_loss: 0.01742\n",
      "Epoch 12/50   -   loss: 0.01887   -   val_loss: 0.01731\n",
      "Epoch 13/50   -   loss: 0.01872   -   val_loss: 0.01722\n",
      "Epoch 14/50   -   loss: 0.01840   -   val_loss: 0.01681\n",
      "Epoch 15/50   -   loss: 0.01812   -   val_loss: 0.01672\n",
      "Epoch 16/50   -   loss: 0.01790   -   val_loss: 0.01652\n",
      "Epoch 17/50   -   loss: 0.01769   -   val_loss: 0.01642\n",
      "Epoch 18/50   -   loss: 0.01754   -   val_loss: 0.01627\n",
      "Epoch 19/50   -   loss: 0.01737   -   val_loss: 0.01627\n",
      "Epoch 20/50   -   loss: 0.01726   -   val_loss: 0.01622\n",
      "Epoch 21/50   -   loss: 0.01716   -   val_loss: 0.01611\n",
      "Epoch 22/50   -   loss: 0.01699   -   val_loss: 0.01606\n",
      "Epoch 23/50   -   loss: 0.01682   -   val_loss: 0.01594\n",
      "Epoch 24/50   -   loss: 0.01684   -   val_loss: 0.01598\n",
      "Epoch 25/50   -   loss: 0.01677   -   val_loss: 0.01598\n",
      "Epoch 26/50   -   loss: 0.01666   -   val_loss: 0.01581\n",
      "Epoch 27/50   -   loss: 0.01653   -   val_loss: 0.01578\n",
      "Epoch 28/50   -   loss: 0.01650   -   val_loss: 0.01574\n",
      "Epoch 29/50   -   loss: 0.01654   -   val_loss: 0.01580\n",
      "Epoch 30/50   -   loss: 0.01641   -   val_loss: 0.01582\n",
      "Epoch 31/50   -   loss: 0.01642   -   val_loss: 0.01580\n",
      "Epoch 32/50   -   loss: 0.01644   -   val_loss: 0.01576\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 33/50   -   loss: 0.01605   -   val_loss: 0.01557\n",
      "Epoch 34/50   -   loss: 0.01584   -   val_loss: 0.01553\n",
      "Epoch 35/50   -   loss: 0.01575   -   val_loss: 0.01552\n",
      "Epoch 36/50   -   loss: 0.01561   -   val_loss: 0.01550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50   -   loss: 0.01555   -   val_loss: 0.01545\n",
      "Epoch 38/50   -   loss: 0.01542   -   val_loss: 0.01545\n",
      "Epoch 39/50   -   loss: 0.01538   -   val_loss: 0.01541\n",
      "Epoch 40/50   -   loss: 0.01529   -   val_loss: 0.01542\n",
      "Epoch 41/50   -   loss: 0.01523   -   val_loss: 0.01538\n",
      "Epoch 42/50   -   loss: 0.01515   -   val_loss: 0.01538\n",
      "Epoch 43/50   -   loss: 0.01507   -   val_loss: 0.01535\n",
      "Epoch 44/50   -   loss: 0.01502   -   val_loss: 0.01533\n",
      "Epoch 45/50   -   loss: 0.01494   -   val_loss: 0.01532\n",
      "Epoch 46/50   -   loss: 0.01490   -   val_loss: 0.01530\n",
      "Epoch 47/50   -   loss: 0.01483   -   val_loss: 0.01531\n",
      "Epoch 48/50   -   loss: 0.01474   -   val_loss: 0.01528\n",
      "Epoch 49/50   -   loss: 0.01474   -   val_loss: 0.01533\n",
      "Epoch 50/50   -   loss: 0.01465   -   val_loss: 0.01532\n",
      "Train fold 7\n",
      "Epoch 1/50   -   loss: 0.42607   -   val_loss: 0.08807\n",
      "Epoch 2/50   -   loss: 0.05071   -   val_loss: 0.02793\n",
      "Epoch 3/50   -   loss: 0.02797   -   val_loss: 0.02366\n",
      "Epoch 4/50   -   loss: 0.02416   -   val_loss: 0.02192\n",
      "Epoch 5/50   -   loss: 0.02196   -   val_loss: 0.02079\n",
      "Epoch 6/50   -   loss: 0.02123   -   val_loss: 0.02010\n",
      "Epoch 7/50   -   loss: 0.02055   -   val_loss: 0.01945\n",
      "Epoch 8/50   -   loss: 0.02010   -   val_loss: 0.01926\n",
      "Epoch 9/50   -   loss: 0.01983   -   val_loss: 0.01888\n",
      "Epoch 10/50   -   loss: 0.01942   -   val_loss: 0.01854\n",
      "Epoch 11/50   -   loss: 0.01957   -   val_loss: 0.01834\n",
      "Epoch 12/50   -   loss: 0.01885   -   val_loss: 0.01833\n",
      "Epoch 13/50   -   loss: 0.01867   -   val_loss: 0.01802\n",
      "Epoch 14/50   -   loss: 0.01836   -   val_loss: 0.01786\n",
      "Epoch 15/50   -   loss: 0.01801   -   val_loss: 0.01764\n",
      "Epoch 16/50   -   loss: 0.01771   -   val_loss: 0.01753\n",
      "Epoch 17/50   -   loss: 0.01753   -   val_loss: 0.01742\n",
      "Epoch 18/50   -   loss: 0.01747   -   val_loss: 0.01732\n",
      "Epoch 19/50   -   loss: 0.01737   -   val_loss: 0.01728\n",
      "Epoch 20/50   -   loss: 0.01719   -   val_loss: 0.01722\n",
      "Epoch 21/50   -   loss: 0.01710   -   val_loss: 0.01709\n",
      "Epoch 22/50   -   loss: 0.01703   -   val_loss: 0.01710\n",
      "Epoch 23/50   -   loss: 0.01686   -   val_loss: 0.01708\n",
      "Epoch 24/50   -   loss: 0.01681   -   val_loss: 0.01701\n",
      "Epoch 25/50   -   loss: 0.01668   -   val_loss: 0.01699\n",
      "Epoch 26/50   -   loss: 0.01671   -   val_loss: 0.01693\n",
      "Epoch 27/50   -   loss: 0.01653   -   val_loss: 0.01691\n",
      "Epoch 28/50   -   loss: 0.01650   -   val_loss: 0.01688\n",
      "Epoch 29/50   -   loss: 0.01656   -   val_loss: 0.01682\n",
      "Epoch 30/50   -   loss: 0.01647   -   val_loss: 0.01687\n",
      "Epoch 31/50   -   loss: 0.01641   -   val_loss: 0.01685\n",
      "Epoch 32/50   -   loss: 0.01640   -   val_loss: 0.01684\n",
      "Epoch 33/50   -   loss: 0.01639   -   val_loss: 0.01684\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 34/50   -   loss: 0.01604   -   val_loss: 0.01670\n",
      "Epoch 35/50   -   loss: 0.01586   -   val_loss: 0.01665\n",
      "Epoch 36/50   -   loss: 0.01574   -   val_loss: 0.01659\n",
      "Epoch 37/50   -   loss: 0.01559   -   val_loss: 0.01654\n",
      "Epoch 38/50   -   loss: 0.01554   -   val_loss: 0.01655\n",
      "Epoch 39/50   -   loss: 0.01546   -   val_loss: 0.01651\n",
      "Epoch 40/50   -   loss: 0.01535   -   val_loss: 0.01647\n",
      "Epoch 41/50   -   loss: 0.01533   -   val_loss: 0.01646\n",
      "Epoch 42/50   -   loss: 0.01525   -   val_loss: 0.01645\n",
      "Epoch 43/50   -   loss: 0.01518   -   val_loss: 0.01644\n",
      "Epoch 44/50   -   loss: 0.01509   -   val_loss: 0.01643\n",
      "Epoch 45/50   -   loss: 0.01503   -   val_loss: 0.01643\n",
      "Epoch 46/50   -   loss: 0.01499   -   val_loss: 0.01639\n",
      "Epoch 47/50   -   loss: 0.01492   -   val_loss: 0.01638\n",
      "Epoch 48/50   -   loss: 0.01488   -   val_loss: 0.01638\n",
      "Epoch 49/50   -   loss: 0.01483   -   val_loss: 0.01639\n",
      "Epoch 50/50   -   loss: 0.01476   -   val_loss: 0.01638\n"
     ]
    }
   ],
   "source": [
    "for seed in range(nstarts):\n",
    "    # seed = 56\n",
    "    print(f'Train seed {seed}')\n",
    "    set_seed(seed)\n",
    "\n",
    "    for n, (tr, te) in enumerate(kfold.split(train_targets, train_targets)):\n",
    "        print(f'Train fold {n+1}')\n",
    "        xtrain, xval = train[tr], train[te]\n",
    "        ytrain, yval = train_targets[tr], train_targets[te]\n",
    "\n",
    "        train_set = MoaDataset(xtrain, ytrain, top_feats)\n",
    "        val_set = MoaDataset(xval, yval, top_feats)\n",
    "\n",
    "        dataloaders = {\n",
    "            'train': DataLoader(train_set, batch_size=batch_size, shuffle=True),\n",
    "            'val': DataLoader(val_set, batch_size=val_batch_size, shuffle=False)\n",
    "        }\n",
    "\n",
    "        model = MoaModel(len(top_feats)).to(device)\n",
    "        checkpoint_path = f'repeat:{seed}_Fold:{n+1}.pt'\n",
    "        optimizer = optim.Adam(model.parameters(), weight_decay=1e-5)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, eps=1e-4, verbose=True)\n",
    "        best_loss = {'train': np.inf, 'val': np.inf}\n",
    "\n",
    "        for epoch in range(nepochs):\n",
    "            epoch_loss = {'train': 0.0, 'val': 0.0}\n",
    "\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()\n",
    "                else:\n",
    "                    model.eval()\n",
    "\n",
    "                running_loss = 0.0\n",
    "\n",
    "                for i, (x, y) in enumerate(dataloaders[phase]):\n",
    "                    x, y = x.to(device), y.to(device)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    with torch.set_grad_enabled(phase=='train'):\n",
    "                        preds = model(x)\n",
    "                        loss = criterion(preds, y)\n",
    "\n",
    "                        if phase=='train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    running_loss += loss.item() / len(dataloaders[phase])\n",
    "\n",
    "                epoch_loss[phase] = running_loss\n",
    "\n",
    "            print(\"Epoch {}/{}   -   loss: {:5.5f}   -   val_loss: {:5.5f}\".format(epoch+1, nepochs, epoch_loss['train'], epoch_loss['val']))\n",
    "\n",
    "            scheduler.step(epoch_loss['val'])\n",
    "\n",
    "            if epoch_loss['val'] < best_loss['val']:\n",
    "                best_loss = epoch_loss\n",
    "                torch.save(model.state_dict(), checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof = np.zeros((len(train), nstarts, ntargets))\n",
    "oof_targets = np.zeros((len(train), ntargets))\n",
    "preds = np.zeros((len(test), ntargets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_log_loss(y_true, y_pred):\n",
    "    metrics = []\n",
    "    for i, target in enumerate(targets):\n",
    "        metrics.append(log_loss(y_true[:, i], y_pred[:, i].astype(float), labels=[0,1]))\n",
    "    return np.mean(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference for seed 0\n",
      "Score for this seed 0.01593\n",
      "Overall score is 0.01593\n"
     ]
    }
   ],
   "source": [
    "for seed in range(nstarts):\n",
    "    print(f\"Inference for seed {seed}\")\n",
    "    seed_targets = []\n",
    "    seed_oof = []\n",
    "    seed_preds = np.zeros((len(test), ntargets, nfolds))\n",
    "    \n",
    "    for n, (tr, te) in enumerate(kfold.split(train_targets, train_targets)):\n",
    "        xval, yval = train[te], train_targets[te]\n",
    "        fold_preds = []\n",
    "        \n",
    "        val_set = MoaDataset(xval, yval, top_feats)\n",
    "        test_set = MoaDataset(test, None, top_feats, mode='test')\n",
    "        \n",
    "        dataloaders = {\n",
    "            'val': DataLoader(val_set, batch_size=val_batch_size, shuffle=False),\n",
    "            'test': DataLoader(test_set, batch_size=val_batch_size, shuffle=False)\n",
    "        }\n",
    "        \n",
    "        checkpoint_path = f'repeat:{seed}_Fold:{n+1}.pt'\n",
    "        model = MoaModel(len(top_feats)).to(device)\n",
    "        model.load_state_dict(torch.load(checkpoint_path))\n",
    "        model.eval()\n",
    "        \n",
    "        for phase in ['val', 'test']:\n",
    "            for i, (x, y) in enumerate(dataloaders[phase]):\n",
    "                if phase == 'val':\n",
    "                    x, y = x.to(device), y.to(device)\n",
    "                elif phase == 'test':\n",
    "                    x = x.to(device)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    batch_preds = model(x)\n",
    "                    \n",
    "                    if phase == 'val':\n",
    "                        seed_targets.append(y)\n",
    "                        seed_oof.append(batch_preds)\n",
    "                    elif phase == 'test':\n",
    "                        fold_preds.append(batch_preds)\n",
    "                    \n",
    "        fold_preds = torch.cat(fold_preds, dim=0).cpu().numpy()\n",
    "        seed_preds[:, :, n] = fold_preds\n",
    "        \n",
    "    seed_targets = torch.cat(seed_targets, dim=0).cpu().numpy()\n",
    "    seed_oof = torch.cat(seed_oof, dim=0).cpu().numpy()\n",
    "    seed_preds = np.mean(seed_preds, axis=2)\n",
    "    \n",
    "    print(\"Score for this seed {:5.5f}\".format(mean_log_loss(seed_targets, seed_oof)))\n",
    "    oof_targets = seed_targets\n",
    "    oof[:, seed, :] = seed_oof\n",
    "    preds += seed_preds / nstarts\n",
    "\n",
    "oof = np.mean(oof, axis=1)\n",
    "print(\"Overall score is {:5.5f}\".format(mean_log_loss(oof_targets, oof)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss[targets] = preds\n",
    "ss.loc[test_features['cp_type']=='ctl_vehicle', targets] = 0\n",
    "ss.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "language": "python",
   "name": "python37064bite8edd735a6ec4a29af499526950cdbdf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
